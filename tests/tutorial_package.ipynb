{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial notebook of rhsegmentor\n",
    "\n",
    "This tutorial guides you throuhg the main use cases of the `rhsegmentor` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: imports\n",
    "\n",
    "Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# imports the rhsegmentor (most important functions are available at the top level of the package)\n",
    "import rhsegmentor as rh\n",
    "from rhsegmentor import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib tk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: look at some sample data\n",
    "\n",
    "The method `load_training_image` allows to read an image and the tracings for training as well. The `auto_transform` option allows to automatically transform the tracings coordinates into the coordinate system of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, names, vertices_s, vertices_e = rh.load_training_image(img_file = \"../sample_newMachine/AG00DA6Z_000002.jpg\",\n",
    "                                                        root_traces_file = \"../sample_newMachine/AG00DA6Z_000002 vertices.csv\",\n",
    "                                                        auto_transform=False)\n",
    "\n",
    "#transform into row-column coordinates\n",
    "vertices_s_RC = utils.flip_XY_RC(vertices_s)\n",
    "vertices_e_RC = utils.flip_XY_RC(vertices_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create training data from the loaded images, the tracings are first transformed into a root-segmentation mask with `root_segmentation_mask`. This function create a np.ndarray mask image containing root-pixels (1), relevant background pixels for making a classification (2) and unclassified pixels (3). To do that, buffer zones are used around the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation mask\n",
    "mask = rh.root_segmentation_mask(im = im,\n",
    "                          vertices_s_RC = vertices_s_RC,\n",
    "                          vertices_e_RC = vertices_e_RC,\n",
    "                          dilatation_radius= 2,\n",
    "                          buffer_radius = 5,\n",
    "                          no_root_radius = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `show_traces` allows to plot an image with the traincing on top (similar to imshow). Use `%matplotlib tk` for pop-up viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "rh.show_traces(vertices_s, vertices_e, im)\n",
    "plt.subplot(1, 2, 2)\n",
    "rh.show_traces(vertices_s, vertices_e, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile a dataset for training\n",
    "\n",
    "The tracings of multiple images are combined to learn a pixel-classifier. To achieve this goal, the following steps are taken:\n",
    "* All images and tracings in `some_folder` are listed\n",
    "* Per image, pixel-level features are computed (texture, gradient image etc.)\n",
    "* The per image, the function `create_root_buffer_background_image` is used to comput the label of every pixel\n",
    "* A fraction is points is sampled (reducing training dataset size and rebalancing it somewhat)\n",
    "* The preveous steps are applied to all images in `some_folder` and combined in a features dataset `X` and labels dataset `Y`\n",
    "\n",
    "The first step only computes labels and features per image and stores them as `npy` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute FEATURES and LABELS for each image in a given folder\n",
    "files_list = utils.listdir_with_path('../sample_newMachine/small/', suffix = \".jpg\")\n",
    "rh.imgs_to_XY_data(img_file_list = files_list,\n",
    "                    root_traces_file_list = None,\n",
    "                    auto_transform = False,\n",
    "                    dilatation_radius = 2,\n",
    "                    buffer_radius = 5,\n",
    "                    no_root_radius = 30,\n",
    "                    sigma_max = 10,\n",
    "                    save_masks_as_im = True,\n",
    "                    save_dir = '../sample_newMachine/small/features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step combines the generated files to create `X` and `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training datasets\n",
    "features_file_list = ['../sample_newMachine/small/features/'+f for f in os.listdir('../sample_newMachine/small/features/') if f[-3:] == \"npy\" and \"FEATURES\" in f]\n",
    "X, Y = rh.compile_training_dataset_from_precomputed_features(features_file_list, sample_fraction=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train a model and save it\n",
    "\n",
    "The compiled dataset is used to train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/RF_AGO_000and002_NTrees-100_TEST.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest classifier (any other classifier)\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                            max_depth=10, max_samples=0.05)\n",
    "clf.fit(X, Y)\n",
    "# dump the model to a file\n",
    "rh.dump_model(clf, '../models/RF_AGO_000and002_NTrees-100_TEST.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load a saved model\n",
    "\n",
    "Select a saved model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rh.load_model('../models/RF_AGO_000and002_NTrees-100_TEST.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load new image to make predictions (and compare with tracings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(\"../sample_newMachine/test_cases/AG00IHWX_000000.jpg\")\n",
    "# compute features\n",
    "features = rh.im2features(im, sigma_max = 10)\n",
    "# predict\n",
    "predicted_segmentation = rh.predict_segmentor(clf, features)\n",
    "# clean detected roots\n",
    "roots = rh.clean_predicted_roots(predicted_segmentation, small_objects_threshold=150, closing_diameter = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw detected roots\n",
    "im_out = rh.draw_detected_roots(roots, im, root_thickness = 7, minimalBranchLength = 10)\n",
    "# measure root properties and show as table\n",
    "rh.measure_roots(roots, root_thickness = 7, minimalBranchLength = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Export the results to a file\n",
    "\n",
    "The lenths, orientation, position etc. of the roots can be exported to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = rh.measure_roots(roots)\n",
    "results_df.to_excel(\"../sample_newMachine/out/measurements.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Automate classification per folder\n",
    "\n",
    "Lists all files in `some_dir`, detects roots and saves the results in a xlsx file. All detected roots are saved for quality checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(\"../sample_newMachine/test_cases/AG00IHWX_000000.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rh.extract_rh_props(im, clf = clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_list = utils.listdir_with_path('../sample_newMachine/test_cases/', suffix = \".jpg\")\n",
    "features_file_list = utils.listdir_with_path('../sample_newMachine/small/', suffix = \".jpg\")\n",
    "save_dir = \"../sample_newMachine/out/\"\n",
    "res = rh.batch_extract_rh_props(file_list=features_file_list, clf = clf, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>orientation</th>\n",
       "      <th>length</th>\n",
       "      <th>approx_check</th>\n",
       "      <th>adjusted_length</th>\n",
       "      <th>adjusted_length_with_sqrt2</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477.160000</td>\n",
       "      <td>183.842921</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>252.539235</td>\n",
       "      <td>Bad approx</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>594.379726</td>\n",
       "      <td>../sample_newMachine/small/AG003B8X000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046.026606</td>\n",
       "      <td>474.975057</td>\n",
       "      <td>-0.352643</td>\n",
       "      <td>124.017761</td>\n",
       "      <td>Bad approx</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>364.190909</td>\n",
       "      <td>../sample_newMachine/small/AG003B8X000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1299.638649</td>\n",
       "      <td>730.645115</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>106.438163</td>\n",
       "      <td>OK</td>\n",
       "      <td>106.438163</td>\n",
       "      <td>106.438163</td>\n",
       "      <td>../sample_newMachine/small/AG003B8X000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1461.243243</td>\n",
       "      <td>763.148148</td>\n",
       "      <td>-0.244384</td>\n",
       "      <td>84.571346</td>\n",
       "      <td>OK</td>\n",
       "      <td>84.571346</td>\n",
       "      <td>84.571346</td>\n",
       "      <td>../sample_newMachine/small/AG003B8X000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1317.775348</td>\n",
       "      <td>802.182903</td>\n",
       "      <td>-0.537929</td>\n",
       "      <td>54.820845</td>\n",
       "      <td>OK</td>\n",
       "      <td>54.820845</td>\n",
       "      <td>54.820845</td>\n",
       "      <td>../sample_newMachine/small/AG003B8X000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>317.220837</td>\n",
       "      <td>1509.621590</td>\n",
       "      <td>0.149442</td>\n",
       "      <td>353.749693</td>\n",
       "      <td>Bad approx</td>\n",
       "      <td>442.000000</td>\n",
       "      <td>493.948268</td>\n",
       "      <td>../sample_newMachine/small/AG00IHWX_000007.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>191.334179</td>\n",
       "      <td>1486.811337</td>\n",
       "      <td>0.395039</td>\n",
       "      <td>224.284518</td>\n",
       "      <td>OK</td>\n",
       "      <td>224.284518</td>\n",
       "      <td>224.284518</td>\n",
       "      <td>../sample_newMachine/small/AG00IHWX_000007.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>100.286811</td>\n",
       "      <td>1514.358175</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>227.724730</td>\n",
       "      <td>OK</td>\n",
       "      <td>227.724730</td>\n",
       "      <td>227.724730</td>\n",
       "      <td>../sample_newMachine/small/AG00IHWX_000007.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>324.590164</td>\n",
       "      <td>1467.551913</td>\n",
       "      <td>0.313729</td>\n",
       "      <td>64.045784</td>\n",
       "      <td>OK</td>\n",
       "      <td>64.045784</td>\n",
       "      <td>64.045784</td>\n",
       "      <td>../sample_newMachine/small/AG00IHWX_000007.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1481.204560</td>\n",
       "      <td>1922.826710</td>\n",
       "      <td>0.211548</td>\n",
       "      <td>130.731184</td>\n",
       "      <td>Bad approx</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>249.267027</td>\n",
       "      <td>../sample_newMachine/small/AG00IHWX_000007.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X            Y  orientation      length approx_check  \\\n",
       "0   1477.160000   183.842921     0.055571  252.539235   Bad approx   \n",
       "1   1046.026606   474.975057    -0.352643  124.017761   Bad approx   \n",
       "2   1299.638649   730.645115     0.023735  106.438163           OK   \n",
       "3   1461.243243   763.148148    -0.244384   84.571346           OK   \n",
       "4   1317.775348   802.182903    -0.537929   54.820845           OK   \n",
       "..          ...          ...          ...         ...          ...   \n",
       "42   317.220837  1509.621590     0.149442  353.749693   Bad approx   \n",
       "43   191.334179  1486.811337     0.395039  224.284518           OK   \n",
       "44   100.286811  1514.358175     0.423810  227.724730           OK   \n",
       "45   324.590164  1467.551913     0.313729   64.045784           OK   \n",
       "46  1481.204560  1922.826710     0.211548  130.731184   Bad approx   \n",
       "\n",
       "    adjusted_length  adjusted_length_with_sqrt2  \\\n",
       "0        561.000000                  594.379726   \n",
       "1        312.000000                  364.190909   \n",
       "2        106.438163                  106.438163   \n",
       "3         84.571346                   84.571346   \n",
       "4         54.820845                   54.820845   \n",
       "..              ...                         ...   \n",
       "42       442.000000                  493.948268   \n",
       "43       224.284518                  224.284518   \n",
       "44       227.724730                  227.724730   \n",
       "45        64.045784                   64.045784   \n",
       "46       225.000000                  249.267027   \n",
       "\n",
       "                                             fname  \n",
       "0    ../sample_newMachine/small/AG003B8X000001.jpg  \n",
       "1    ../sample_newMachine/small/AG003B8X000001.jpg  \n",
       "2    ../sample_newMachine/small/AG003B8X000001.jpg  \n",
       "3    ../sample_newMachine/small/AG003B8X000001.jpg  \n",
       "4    ../sample_newMachine/small/AG003B8X000001.jpg  \n",
       "..                                             ...  \n",
       "42  ../sample_newMachine/small/AG00IHWX_000007.jpg  \n",
       "43  ../sample_newMachine/small/AG00IHWX_000007.jpg  \n",
       "44  ../sample_newMachine/small/AG00IHWX_000007.jpg  \n",
       "45  ../sample_newMachine/small/AG00IHWX_000007.jpg  \n",
       "46  ../sample_newMachine/small/AG00IHWX_000007.jpg  \n",
       "\n",
       "[97 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all test images in folder\n",
    "features_file_list = utils.listdir_with_path('../sample_newMachine/test_cases/', suffix = \".jpg\")\n",
    "save_dir = \"../sample_newMachine/out/\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for fname in features_file_list:\n",
    "    # read image\n",
    "    im = io.imread(fname)\n",
    "    # compute features\n",
    "    features = rh.im2features(im, sigma_max = 10)\n",
    "    # predict\n",
    "    predicted_segmentation = rh.predict_segmentor(clf, features)\n",
    "    # clean detected roots\n",
    "    roots = rh.clean_predicted_roots(predicted_segmentation, small_objects_threshold=150, closing_diameter = 4)\n",
    "    # compute root properties\n",
    "    results_df = rh.measure_roots(roots, root_thickness = 7, minimalBranchLength = 10)\n",
    "    results_df[\"fname\"] = fname\n",
    "    # append to results list\n",
    "    all_results.append(results_df)\n",
    "    # save image for quality check\n",
    "    fname_save = utils.get_save_fname(fname = fname,\n",
    "                                      save_dir = save_dir,\n",
    "                                      suffix = \"result.png\")\n",
    "    rh.save_detected_roots_im(clean_root_image = roots,\n",
    "                              original_im = im,\n",
    "                              fname = fname_save,\n",
    "                              root_thickness = 7,\n",
    "                              minimalBranchLength = 10)\n",
    "\n",
    "# concatenate and save in excel-format\n",
    "pd.concat(all_results).to_excel(os.path.join(save_dir,\"measurements.xlsx\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09605cd2bc0aa78d59dab4b68b44be16a9a5d52cf560cda528d1db29b8f55ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
