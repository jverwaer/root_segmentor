{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial notebook of rhsegmentor\n",
    "\n",
    "This tutorial guides you throuhg the main use cases of the `rhsegmentor` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: imports\n",
    "\n",
    "Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# imports the rhsegmentor (most important functions are available at the top level of the package)\n",
    "import rhsegmentor as rh\n",
    "from rhsegmentor import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib tk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: look at some sample data\n",
    "\n",
    "The method `load_training_image` allows to read an image and the tracings for training as well. The `auto_transform` option allows to automatically transform the tracings coordinates into the coordinate system of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, names, vertices_s, vertices_e = rh.load_training_image(img_file = \"../sample_newMachine/AG00DA6Z_000002.jpg\",\n",
    "                                                        root_traces_file = \"../sample_newMachine/AG00DA6Z_000002 vertices.csv\",\n",
    "                                                        auto_transform=False)\n",
    "\n",
    "#transform into row-column coordinates\n",
    "vertices_s_RC = utils.flip_XY_RC(vertices_s)\n",
    "vertices_e_RC = utils.flip_XY_RC(vertices_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create training data from the loaded images, the tracings are first transformed into a root-segmentation mask with `root_segmentation_mask`. This function create a np.ndarray mask image containing root-pixels (1), relevant background pixels for making a classification (2) and unclassified pixels (3). To do that, buffer zones are used around the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation mask\n",
    "mask = rh.root_segmentation_mask(im = im,\n",
    "                          vertices_s_RC = vertices_s_RC,\n",
    "                          vertices_e_RC = vertices_e_RC,\n",
    "                          dilatation_radius= 2,\n",
    "                          buffer_radius = 5,\n",
    "                          no_root_radius = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `show_traces` allows to plot an image with the traincing on top (similar to imshow). Use `%matplotlib tk` for pop-up viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "rh.show_traces(vertices_s, vertices_e, im)\n",
    "plt.subplot(1, 2, 2)\n",
    "rh.show_traces(vertices_s, vertices_e, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile a dataset for training\n",
    "\n",
    "The tracings of multiple images are combined to learn a pixel-classifier. To achieve this goal, the following steps are taken:\n",
    "* All images and tracings in `some_folder` are listed\n",
    "* Per image, pixel-level features are computed (texture, gradient image etc.)\n",
    "* The per image, the function `create_root_buffer_background_image` is used to comput the label of every pixel\n",
    "* A fraction is points is sampled (reducing training dataset size and rebalancing it somewhat)\n",
    "* The preveous steps are applied to all images in `some_folder` and combined in a features dataset `X` and labels dataset `Y`\n",
    "\n",
    "The first step only computes labels and features per image and stores them as `npy` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute FEATURES and LABELS for each image in a given folder\n",
    "files_list = utils.listdir_with_path('../sample_newMachine/small/', suffix = \".jpg\")\n",
    "rh.imgs_to_XY_data(img_file_list = files_list,\n",
    "                    root_traces_file_list = None,\n",
    "                    auto_transform = False,\n",
    "                    dilatation_radius = 2,\n",
    "                    buffer_radius = 5,\n",
    "                    no_root_radius = 30,\n",
    "                    sigma_max = 10,\n",
    "                    save_masks_as_im = True,\n",
    "                    save_dir = '../sample_newMachine/small/features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step combines the generated files to create `X` and `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training datasets\n",
    "features_file_list = ['../sample_newMachine/small/features/'+f for f in os.listdir('../sample_newMachine/small/features/') if f[-3:] == \"npy\" and \"FEATURES\" in f]\n",
    "X, Y = rh.compile_training_dataset_from_precomputed_features(features_file_list, sample_fraction=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train a model and save it\n",
    "\n",
    "The compiled dataset is used to train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/RF_AGO_000and002_NTrees-100_TEST.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit random forest classifier (any other classifier)\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                            max_depth=10, max_samples=0.05)\n",
    "clf.fit(X, Y)\n",
    "# dump the model to a file\n",
    "rh.dump_model(clf, '../models/RF_AGO_000and002_NTrees-100_TEST.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load a saved model\n",
    "\n",
    "Select a saved model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rh.load_model('../models/RF_AGO_000and002_NTrees-100_TEST.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load new image to make predictions (and compare with tracings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(\"../sample_newMachine/test_cases/AG00IHWX_000000.jpg\")\n",
    "# compute features\n",
    "features = rh.im2features(im, sigma_max = 10)\n",
    "# predict\n",
    "predicted_segmentation = rh.predict_segmentor(clf, features)\n",
    "# clean detected roots\n",
    "roots = rh.clean_predicted_roots(predicted_segmentation, small_objects_threshold=150, closing_diameter = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw detected roots\n",
    "im_out = rh.draw_detected_roots(roots, im, root_thickness = 7, minimalBranchLength = 10)\n",
    "# measure root properties and show as table\n",
    "rh.measure_roots(roots, root_thickness = 7, minimalBranchLength = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Export the results to a file\n",
    "\n",
    "The lenths, orientation, position etc. of the roots can be exported to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = rh.measure_roots(roots)\n",
    "results_df.to_excel(\"../sample_newMachine/out/measurements.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Automate classification per folder\n",
    "\n",
    "Lists all files in `some_dir`, detects roots and saves the results in a xlsx file. All detected roots are saved for quality checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all test images in folder\n",
    "features_file_list = utils.listdir_with_path('../sample_newMachine/test_cases/', suffix = \".jpg\")\n",
    "save_dir = \"../sample_newMachine/out/\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for fname in features_file_list:\n",
    "    # read image\n",
    "    im = io.imread(fname)\n",
    "    # compute features\n",
    "    features = rh.im2features(im, sigma_max = 10)\n",
    "    # predict\n",
    "    predicted_segmentation = rh.predict_segmentor(clf, features)\n",
    "    # clean detected roots\n",
    "    roots = rh.clean_predicted_roots(predicted_segmentation, small_objects_threshold=150, closing_diameter = 4)\n",
    "    # compute root properties\n",
    "    results_df = rh.measure_roots(roots, root_thickness = 7, minimalBranchLength = 10)\n",
    "    results_df[\"fname\"] = fname\n",
    "    # append to results list\n",
    "    all_results.append(results_df)\n",
    "    # save image for quality check\n",
    "    fname_save = utils.get_save_fname(fname = fname,\n",
    "                                      save_dir = save_dir,\n",
    "                                      suffix = \"result.png\")\n",
    "    rh.save_detected_roots_im(clean_root_image = roots,\n",
    "                              original_im = im,\n",
    "                              fname = fname_save,\n",
    "                              root_thickness = 7,\n",
    "                              minimalBranchLength = 10)\n",
    "\n",
    "# concatenate and save in excel-format\n",
    "pd.concat(all_results).to_excel(os.path.join(save_dir,\"measurements.xlsx\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09605cd2bc0aa78d59dab4b68b44be16a9a5d52cf560cda528d1db29b8f55ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
