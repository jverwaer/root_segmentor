{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rhsegmentor: root hair segmentation\n",
    "\n",
    "**rhsegmentor** is a Python package simplifies the bulk segmentation and analysis of root hair images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "This tutorial guides you throuhg the main use cases of the `rhsegmentor` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: imports\n",
    "\n",
    "Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# imports the rhsegmentor (most important functions are available at the top level of the package)\n",
    "import rhsegmentor as rh\n",
    "from rhsegmentor import utils\n",
    "from rhsegmentor import sample_data_generator\n",
    "\n",
    "# basic imports for visualization, image loading and classification\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import io\n",
    "\n",
    "# magic function (ony for interactive useage)\n",
    "%matplotlib tk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: look at some sample data\n",
    "\n",
    "The functions `create_training_data` and `create_test_data` in the code fragment below create training and test data (both images and labels) that will be used in this tutorial.\n",
    "\n",
    "The method `load_training_image` allows to read an image and the tracings for training as well. The `auto_transform` option allows to automatically transform the tracings coordinates into the coordinate system of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test folders\n",
    "sample_data_generator.create_training_data()\n",
    "sample_data_generator.create_test_data()\n",
    "\n",
    "# load first image\n",
    "im, names, vertices_s, vertices_e = rh.load_training_image(img_file = \"./trainData/img1.jpg\",\n",
    "                                                        root_traces_file = \"./trainData/img1 vertices.csv\",\n",
    "                                                        auto_transform=False)\n",
    "\n",
    "#transform into row-column coordinates\n",
    "vertices_s_RC = utils.flip_XY_RC(vertices_s)\n",
    "vertices_e_RC = utils.flip_XY_RC(vertices_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create training data from the loaded images, the tracings are first transformed into a root-segmentation mask with `root_segmentation_mask`. This function create a np.ndarray mask image containing root-pixels (1), relevant background pixels for making a classification (2) and unclassified pixels (3). To do that, buffer zones are used around the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation mask\n",
    "mask = rh.root_segmentation_mask(im = im,\n",
    "                          vertices_s_RC = vertices_s_RC,\n",
    "                          vertices_e_RC = vertices_e_RC,\n",
    "                          dilatation_radius= 2,\n",
    "                          buffer_radius = 5,\n",
    "                          no_root_radius = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `show_traces` allows to plot an image with the traincing on top (similar to imshow). Use `%matplotlib tk` for pop-up viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "rh.show_traces(vertices_s, vertices_e, im)\n",
    "plt.subplot(1, 2, 2)\n",
    "rh.show_traces(vertices_s, vertices_e, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile a dataset for training\n",
    "\n",
    "The tracings of multiple images are combined to learn a pixel-classifier. To achieve this goal, the following steps are taken:\n",
    "* All images and tracings in `./trainData` are listed\n",
    "* The function `imgs_to_XY_data` performs the following tasks:\n",
    "    * Per image, pixel-level features are computed (texture, gradient image etc.)\n",
    "    * Subsequently, per image, the the label of every pixel is computed (using a call to `create_root_buffer_background_image`)\n",
    "* The function `compile_training_dataset_from_precomputed_features` performs the following tasks:\n",
    "    * A fraction of  training points is sampled (reducing training dataset size and rebalancing it somewhat)\n",
    "    * Selected points are and combined in a features dataset `X` and labels dataset `Y`\n",
    "\n",
    "The first step only computes labels and features per image and stores them as `npy` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute FEATURES and LABELS for each image in a given folder\n",
    "files_list = utils.listdir_with_path('./trainData', suffix = \".jpg\")\n",
    "rh.imgs_to_XY_data(img_file_list = files_list,\n",
    "                    root_traces_file_list = None,\n",
    "                    auto_transform = False,\n",
    "                    dilatation_radius = 2,\n",
    "                    buffer_radius = 5,\n",
    "                    no_root_radius = 30,\n",
    "                    sigma_max = 10,\n",
    "                    save_masks_as_im = True,\n",
    "                    save_dir = './trainData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step combines the generated files to create `X` and `Y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training datasets\n",
    "features_file_list = utils.listdir_with_path('./trainData', suffix = \"FEATURES.npy\")\n",
    "X, Y = rh.compile_training_dataset_from_precomputed_features(features_file_list, sample_fraction=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train a model and save it\n",
    "\n",
    "The compiled dataset is used to train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest classifier (any other classifier)\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                            max_depth=10, max_samples=0.05)\n",
    "clf.fit(X, Y)\n",
    "# dump the model to a file\n",
    "os.mkdir(\"./models\")\n",
    "rh.dump_model(clf, './models/RF_demo.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load a saved model\n",
    "\n",
    "Select a saved model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rh.load_model('./models/RF_demo.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load new image to make predictions (and compare with tracings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread(\"./testData/img4.jpg\")\n",
    "# compute features\n",
    "features = rh.im2features(im, sigma_max = 10)\n",
    "# predict\n",
    "predicted_segmentation = rh.predict_segmentor(clf, features)\n",
    "# clean detected roots\n",
    "roots = rh.clean_predicted_roots(predicted_segmentation, small_objects_threshold=150, closing_diameter = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw detected roots\n",
    "im_out = rh.draw_detected_roots(roots, im, root_thickness = 7, minimalBranchLength = 10)\n",
    "# measure root properties and show as table\n",
    "rh.measure_roots(roots, root_thickness = 7, minimalBranchLength = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Export the results to a file\n",
    "\n",
    "The lenths, orientation, position etc. of the roots can be exported to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = rh.measure_roots(roots)\n",
    "results_df.to_excel(\"./measurements.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Automate classification per folder\n",
    "\n",
    "List all files in `./testData`, detect roots and save the results in a xlsx file. All detected roots are saved for quality checking (in `save_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all .jpg files in ./testData\n",
    "img_list = utils.listdir_with_path('./testData', suffix = \".jpg\")\n",
    "# batch processs all test images\n",
    "save_dir = \"./testData\"\n",
    "result_df = rh.batch_extract_rh_props(file_list=img_list,\n",
    "                                      clf = clf,\n",
    "                                      save_dir=save_dir)\n",
    "# save final result in xlsx format\n",
    "result_df.to_excel(\"measurements_all.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09605cd2bc0aa78d59dab4b68b44be16a9a5d52cf560cda528d1db29b8f55ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
